\documentclass[aspectratio=169,11pt]{beamer}
\usepackage{tikz}
\usepackage{mathtools}
\usepackage{lmodern}      % replaces Computer Modern with Latin Modern
\usepackage{inconsolata}
\usepackage{multirow}
\usepackage[style=authoryear-comp,url=false,date=year,doi=false,isbn=false,eprint=true,maxnames=1,minnames=1,backend=biber,natbib=true]{biblatex}
% ------------------------------------------------------------
% MIT COLOR PALETTE  (from MIT Brand Guidelines)
% ------------------------------------------------------------
\definecolor{mitred}{HTML}{A31F34}       % Primary MIT rednn
\definecolor{mitdarkgray}{HTML}{545454}  % Neutral dark gray
\definecolor{mitlightgray}{HTML}{C7C7C7} % Light gray
\definecolor{mitorange}{HTML}{D56F00}    % Secondary accent
\definecolor{mitblue}{HTML}{8A8BFF}      % Accent cool tone

% ------------------------------------------------------------
% APPLY TO TITLES
% ------------------------------------------------------------
% Title of the entire talk (front page)
\setbeamercolor{title}{fg=mitred}
\setbeamercolor{subtitle}{fg=mitdarkgray}

% Frame title (top of each slide)
\setbeamercolor{frametitle}{fg=mitred}
\setbeamercolor{framesubtitle}{fg=mitdarkgray}

% Optional: section headings / TOC colors
\setbeamercolor{section title}{fg=mitred}
\setbeamercolor{subsection title}{fg=mitdarkgray}

% --- Bullets / enumeration (structure color drives itemize/enumerate) ---
\setbeamercolor{structure}{fg=mitred}              % bullets, numbers, mini-frames
\setbeamercolor{itemize item}{fg=mitred}
\setbeamercolor{itemize subitem}{fg=mitdarkgray}
\setbeamercolor{enumerate item}{fg=mitred}
\setbeamercolor{enumerate subitem}{fg=mitdarkgray}

% --- Captions (Figure/Table labels & text) ---
\setbeamercolor{caption name}{fg=mitred}           % “Figure”, “Table”
\setbeamercolor{caption}{fg=mitdarkgray}           % caption body text
% Optional: show numbers on captions
% \setbeamertemplate{caption}[numbered]

% --- Blocks ---
\setbeamertemplate{blocks}[rounded][shadow=false]  % or shadow=true for dropshadow
% Normal block: neutral title, neutral body
\setbeamercolor{block title}{fg=black,bg=mitorange!20}
\setbeamercolor{block body}{fg=mitdarkgray,bg=mitorange!20}
% Alert block: MIT red title; body neutral
\setbeamercolor{block title alerted}{fg=black,bg=mitred!20}
\setbeamercolor{block body alerted}{fg=mitdarkgray,bg=mitred!20}
% Example block: cool accent for contrast
\setbeamercolor{block title example}{fg=black,bg=mitdarkgray!20}
\setbeamercolor{block body example}{fg=mitdarkgray,bg=mitdarkgray!20}

% --- Emphasis & inline alerts ---
\setbeamercolor{alerted text}{fg=mitred}           % \alert{...}
\setbeamercolor{example text}{fg=mitblue}

% --- Navigation symbols / progress bars (if your theme uses palettes) ---
\setbeamercolor{palette primary}{fg=white,bg=mitred}
\setbeamercolor{palette secondary}{fg=white,bg=mitdarkgray}
\setbeamercolor{palette tertiary}{fg=white,bg=mitdarkgray}
\setbeamercolor{palette quaternary}{fg=white,bg=mitdarkgray}

% --- Rules, separators, fine lines (optional) ---
\setbeamercolor{separation line}{bg=mitlightgray}
\setbeamercolor{fine separation line}{bg=mitlightgray}

% --- Links ---
\hypersetup{
  colorlinks=true,
  linkcolor=mitred,        % TOC/internal links
  urlcolor=mitred,         % URLs
  citecolor=mitdarkgray    % citations (neutral)
}

\setbeamersize{text margin left=0.5cm, text margin right=0.5cm}


% \setbeamertemplate{footline}[frame number]
\setbeamertemplate{navigation symbols}{}

\setbeamertemplate{footline}{
  \leavevmode%
  \hfill%
  \usebeamerfont{footline}
  \usebeamercolor[fg]{footline}
  \tiny Sungho Shin--- \href{mailto:sushin@mit.edu}{sushin@mit.edu}\; 
  \insertframenumber/\inserttotalframenumber
  \kern1em%
  \vskip3pt
}

% \setbeamertemplate{footline}{%
%   \leavevmode%
%   \hbox to \paperwidth{%
%     \tiny
%     \hspace{.3ex}
%     Sungho Shin---\url{sushin@mit.edu}%
%     \hfil%
%     \insertshorttitle%
%     \hfil%
%     \insertframenumber{}/\inserttotalframenumber
%     \hspace{.3ex}%
%   }%
%   \vspace*{.3ex}%
% }

\setbeamercolor{footline}{fg=mitdarkgray} % or mitred if you like the accent
\setbeamerfont{footline}{size=\scriptsize} % adjust if too big



% \DeclareDelimFormat[bib]{nametitledelim}{\newline\bibsentence}
\addbibresource{shin.bib}
\AtEveryCitekey{\clearfield{pages}} 
\AtEveryCitekey{\clearfield{volume}}
\AtEveryCitekey{\clearfield{number}}
\AtEveryCitekey{\clearfield{primaryclass}}


% % Only print family name(s), but allow et al. when truncated
% \DeclareNameFormat{author}{%
%   \ifthenelse{\value{listcount}=1}
%     {\namepartfamily} % print first name as last name
%     {\ifnumgreater{\value{listcount}}{\value{liststop}}
%         {\addspace et al.} % print "et al." when beyond maxnames
%         {\namepartfamily}} % otherwise print the next last name
% }
% \DeclareNameAlias{default}{last} % = Lastname, F.


\newcommand{\refbr}[2][]{%
  \begin{tikzpicture}[remember picture, overlay,inner sep=3pt,xscale=0.9,transform shape]  
    \node[anchor=south west,align=left,font=\tiny,color=mitdarkgray,text width=1.15\linewidth,yshift=8pt] at (current page.south west) {#1 #2};
  \end{tikzpicture}%
}

\newcommand{\joint}[2][]{% 
  \begin{tikzpicture}[remember picture, overlay, inner sep = 3pt,xscale=0.9,transform shape]
    \node[anchor=south west,align=left,font=\tiny,color=mitdarkgray] at (current page.south west) {#1 #2};  
  \end{tikzpicture}%
}

\graphicspath{{figs/}}

\title[Nonlinear Optimization on GPUs]{Solving Large-Scale, Sparse, Constrained Nonlinear Optimization Problems on GPUs}
\subtitle{Pivoting-Free Interior Point Methods}
\author{
  Sungho Shin\\
  \url{shin.mit.edu}
}
\institute{
  Massachusetts Institute of Technology
}

\date{2025 INFORMS Annual Meeting \\ October 27, 2025}

\begin{document}

\frame{
  \titlepage
  \joint{
    Joint work with:
    Alexis Montoison (Argonne),
    François Pacaud (MINES-Paris),
    Mihai Anitescu (Argonne)
  }
} % Title page

\begin{frame}{Who are we?}
  \begin{center}
    \url{https://madsuite.org/}\\[.25in]    
    \includegraphics[width=.8in]{montoison.jpeg}
    \includegraphics[width=.8in]{pacaud.jpeg}
    \includegraphics[width=.8in]{shin.jpeg}
    \includegraphics[width=.8in]{anitescu.jpeg}
  \end{center}
  \begin{itemize}
  \item Alexis Montoison @ Argonne National Lab
  \item François Pacaud @ MINES Paris-PSL (an ANL alumnus)
  \item Sungho Shin @ MIT (an ANL alumnus)
  \item Mihai Anitescu @ Argonne National Lab
  \item and friends... Michael Saunders, Dominic Orban, Armin Nurkanović, Anton Pozharskiy, Jean-Baptiste Caillau, ...
  \end{itemize}
\end{frame}

% ---------------------------
\section{Motivation}
% ---------------------------
\begin{frame}{GPU-based optimization}
  \begin{itemize}
  \item What is GPU? ---many-core accelerator with high memory bandwidth
  \item Traditionally used for graphics, now widely used for ML/AI workloads
  \item Classical optimization (mathematical program; not ML training problems) has been thought to be \alert{unsuitable} for GPUs
  \item Many state-of-the-art solvers (on CPUs) rely on \alert{sparse direct factorizations}, which has been considered \alert{difficult} to implement efficiently on GPUs
  \item This status quo is changing---the focus of this talk
  \end{itemize}
\end{frame}

\begin{frame}{GPU-based optimization: current landscape}
  \begin{itemize}
  \item \alert{Factoriation-free methods} have been the dominant approach
    \begin{itemize}
    \item PDLP: Primal-dual first-order methods \citep{applegatePracticalLargeScaleLinear2022,luCuPDLPFurtherEnhanced2025}
    \item {PCG}-based algorithms for convex QPs \citep{schubigerGPUAccelerationADMM2020}
    \item ALM + IPM + PCG for nonlinear problems \citep{caoAugmentedLagrangianInteriorpoint2016}
    \end{itemize}
  \item Factoriztion-free methods only rely on \alert{GPU-friendly kernels}---\alert{\texttt{spmv}, \texttt{axpy}, \texttt{map}, \texttt{mapreduce}}---makes them easy to implement on GPUs
  \item Scale to extremely large problems \alert{but achieving high precision is difficult}
  \item Can we implement \alert{second-order methods} with \alert{sparse direct solvers} on GPUs?
  \end{itemize}
  \refbr{
    \fullcite{applegatePracticalLargeScaleLinear2022}\\
    \fullcite{luCuPDLPFurtherEnhanced2025}\\
    \fullcite{schubigerGPUAccelerationADMM2020}\\
    \fullcite{caoAugmentedLagrangianInteriorpoint2016}
  }
\end{frame}

% ---------------------------
\section{Problem Setting: NLPs}
% ---------------------------
\begin{frame}{Our problem setting}{Large-scale, sparse, constrained nonlinear programs}
  \begin{itemize}
  \item \only<1>{
      We consider:
      \begin{align*}
        \min_{x^\flat\leq x \leq x^\sharp}&\; f(x) \\
        \text{s.t.}&\; g^\flat\leq g(x)\leq g^\sharp,
      \end{align*}
    }
    \only<2>{
      WLOG (via $a=b \iff a \geq b,\; b\geq a$), we consider:
      \begin{align*}
        \min_{x\in\mathbb{R}^n}&\; f(x) \\
        \text{s.t.}&\; g(x)\geq 0,
      \end{align*}
    }
    ... but will particularly focus on:
    \begin{itemize}
    \item $f:\mathbb{R}^n\to\mathbb{R}$ and $g:\mathbb{R}^n\to\mathbb{R}^m$ twice continuously differentiable
    \item $n$ and $m$ are large (millions or more)
    \item $\nabla g(x)$ and $\nabla^2_{xx} L(x,\lambda)$ are \alert{sparse} (tens of nonzeros per row)---$L(\cdot,\cdot)$ is the Lagrangian
    \end{itemize}
  \item Generally \alert{nonconvex}---we only seek \alert{local solutions}
  \item Most important instances (e.g., energy systems, optimal control) fall into this category
  \item Most existing solvers (e.g., Ipopt, KNITRO) are optimized for such problems
  \end{itemize}
\end{frame}

% ---------------------------
\section{Software Structure}
% ---------------------------
\newcommand{\kktsystem}{%
  \begin{align*}
    \underbrace{
    \begin{bmatrix}
      \nabla^2_{x x} L(x,s,\lambda) + \delta_p I & & \nabla g(x)^\top
      \\ & S^{-1}\Lambda &  -I
      \\ \nabla g(x) & -I &  - \delta_d I
    \end{bmatrix}
    }_{\text{KKT matrix}}
    \underbrace{
    \begin{bmatrix}
      \phantom{-}d_x \\
      \phantom{-}d_s \\
      -d_\lambda
    \end{bmatrix}}_{\text{step direction}} =
    -\underbrace{\begin{bmatrix}
      \nabla f(x) - \nabla g(x)^\top \lambda\\
      \Lambda e - \mu S^{-1}e \\
      g(x) - s\\
    \end{bmatrix}}_{\text{residual to KKT conditions}},
  \end{align*}
}
\begin{frame}{NLP software stack---either on CPUs or GPUs}{{(1) algebraic modeling system}, {(2) NLP solver}, and {(3) sparse, direct linear solver}}
  \begin{itemize}
  \item \alert{Algebraic modeling systems} (e.g., JuMP, AMPL, CasADi) generate \alert{callback functions---$f(\cdot)$, $g(\cdot)$, $\nabla f(\cdot)$, $\nabla g(\cdot)$, $\nabla^2_{xx} L(\cdot,\cdot)$}---for \alert{NLP solvers}
  \item \alert{NLP solvers} (e.g., Ipopt, KNITRO) form \alert{KKT systems} to find step direction:
  \kktsystem
    where $s$ is the slack variable, $S=\text{diag}(s)$, $\Lambda=\text{diag}(\lambda)$, and $\delta_p,\delta_d\geq 0$ are primal-dual regularization parameters
  \item \alert{Sparse, direct linear solvers} (e.g., MA27, PARDISO) factorize and solve KKT systems; iterative method is typically not an option due to ill-conditioning
  % \item \alert{All on GPUs}: modeling, AD, and linear algebra
  % \item With sparse AD on GPUs, \textbf{derivative evaluation cost fades}
  % \item \textbf{Main challenge}: parallel solution of \textbf{KKT systems}
  % \item Other components (line search, barrier updates, heuristics, inertia correction) are not serial bottlenecks
  % \item \textbf{Focus today}: nonlinear solver + numerical linear algebra
  \end{itemize}
\end{frame}


\begin{frame}{Full NLP software stack on GPU---is it possible?}{{(1) algebraic modeling system}, {(2) NLP solver}, and {(3) sparse, direct linear solver}}
  \begin{itemize}
  \item Partially porting on GPU (e.g., AD or linear algebra only) is not sufficient---will be bottlenecked by CPU--GPU communication. We need \alert{all three components on GPU}
  \item Porting \alert{algebraic modeling system} is relatively straightforward. ExaModels.jl provides GPU-compatible modeling capabilities \citep{shinAcceleratingOptimalPower2024}---not the focus today
  \item Porting \alert{direct linear solver} is more non-trivial; as of now, \alert{there is no drop-in replacement of MA27 on GPUs}
  \end{itemize}
  \begin{block}{Our approach}
    \alert{Adapt interior-point method for NLPs} so that it can work with \alert{GPU direct linear solvers} with (relatively) limited capabilities
  \end{block}
  \refbr{
    \fullcite{shinAcceleratingOptimalPower2024}
  }
\end{frame}
% ---------------------------
\section{Pivoting \& Inertia}
% ---------------------------

\begin{frame}{Sparse direct solvers within interior-point methods}
  \begin{alertblock}{LBL$^\top$ factorization}
    \vspace{-1em}
    \begin{align*}
      \begin{bmatrix}
        \nabla^2_{x x} L(x,s,\lambda) + \delta_p I & & \nabla g(x)^\top
        \\ & S^{-1}\Lambda &  -I
        \\ \nabla g(x) & -I &  - \delta_d I
      \end{bmatrix}
      =
      P\times Q\times L\times B\times L^\top\times  Q^\top\times  P^\top
    \end{align*}
  \end{alertblock}
  \begin{itemize}
  \item $P$: Fill-in-reducing (and parallel-friendly) re-ordering (re-used across IPM iterations)
  \item $Q$: Pivoting (computed on-the-fly during factorization)
  \item $LBL^\top$: Factorization of permuted matrix
  \item Additionally, pivots may be \alert{perturbed}, which must be corrected via \alert{iterative refinement}
  \item Factorization reveals inertia---number of $+$, $0$, and $-$ eigenvalues; primal-dual regularization $(\delta_p,\delta_d)$ is adjusted to achieve correct inertia \citep{wachterImplementationInteriorpointFilter2006}; this can be merged with pivot perturbation \citep{nocedalNumericalOptimization2006}
  \end{itemize}
  \refbr{
    \fullcite{wachterImplementationInteriorpointFilter2006}\\
    \fullcite{nocedalNumericalOptimization2006}
  }
\end{frame}

\begin{frame}{Pivoting-free IPM}{\cite{montoisonGPUImplementationSecondOrder2025}}
  \begin{itemize}
  \item Numerical pivoting is \alert{difficult} to implement on GPUs \citep{swirydowiczLinearSolversPower2022} because row swapping can potentially \alert{destroy parallelism}
  \item Existing GPU solvers (e.g., cuDSS) \alert{don't have adequately robust pivoting strategies}; currently only have partial pivoting and pivot perturbation \citep{nvidiaNVIDIACuDSSPreview}
  \item Factorization may fail without \alert{numerical pivoting}, unless
    \begin{itemize}
    \item \alert{Symmetric quasi-definite} (SQD): factorization exists \citep{vanderbeiSymmetricQuasidefiniteMatrices1995} 
    \item \alert{Symmetric positive definite} (SPD): factorization exists and numerically stable
    \end{itemize}
    However, \alert{KKT systems for NLPs are generally indefinite}
  \item When pivoting is not required, \alert{GPU sparse direct solvers can be very efficient}
  \end{itemize}
  \begin{center}
    \it
    \only<1>{\alert{Can we make IPM pivoting-free?}}
    \only<2>{(For now) can we reformulate KKT systems to be SPD or SQD?}
  \end{center}
  \refbr{
    \fullcite{montoisonGPUImplementationSecondOrder2025}\\
    \fullcite{vanderbeiSymmetricQuasidefiniteMatrices1995}\\
    \fullcite{swirydowiczLinearSolversPower2022}\\
    \fullcite{nvidiaNVIDIACuDSSPreview}
  }
\end{frame}

% ---------------------------
\section{Option 1: Lifted KKT}
% ---------------------------
\begin{frame}{Option 1: Lifted KKT system}{\cite{shinAcceleratingOptimalPower2024}}
\begin{itemize}
\item First, relax equalities by small enough $\tau$  (the same as solver tolerances):
  \begin{align*}
    -\tau\leq h(x)\leq  \tau
  \end{align*}
\item \alert{Condense} the KKT system by eliminating slack/dual variables:
  \begin{align*}
    &\begin{bmatrix}
      \nabla^2_{x x} L(x,s,\lambda) + \delta_p I & & \nabla g(x)^\top
      \\ & S^{-1}\Lambda &  -I
      \\ \nabla g(x) & -I &  - \delta_d I
    \end{bmatrix}
      \begin{bmatrix}
        \phantom{-}d_x \\
        \phantom{-}d_s \\
        -d_\lambda
      \end{bmatrix}
      =      
      -\begin{bmatrix}
        \nabla f(x) - \nabla g(x)^\top \lambda\\
        \Lambda e - \mu S^{-1}e \\
        g(x) - s\\
      \end{bmatrix}
    \\
    &\iff
    \Big(\underbrace{\nabla^2_{xx} L(x,s,\lambda) + \delta_p I + \nabla g(x)^\top (\delta_d I + \Lambda^{-1} S)^{-1} \nabla g(x) }_{\text{\alert{SPD iff the original system has correct inertia}}}\Big) d_x = - r_p \; \\
    &\phantom{\iff\;\;}\text{\color{mitdarkgray}(and some easy-to-solve equations)}
  \end{align*}
\item Enables numerically stable factorization \alert{without pivoting or excessive regularization}
\end{itemize}
\refbr{
  \fullcite{shinAcceleratingOptimalPower2024}
}
\end{frame} 

\begin{frame}{Option 1: Lifted KKT---numerical results (AC OPF)}{\cite{montoisonGPUImplementationSecondOrder2025}}
  \begin{center}
    \scriptsize
    \begin{tabular}{|c|c|c|cc|cc|cc|cc|}
      \hline
      &\multirow{ 3}{*}{\bfseries Tol} & \multirow{ 3}{*}{\bfseries Solver} & \multicolumn{2}{c|}{\textbf{Small}}& \multicolumn{2}{c|}{\textbf{Medium}}& \multicolumn{2}{c|}{\textbf{Large}}& \multicolumn{2}{c|}{\multirow{2}{*}{\textbf{Total}}}\\
      &&& \multicolumn{2}{c|}{nnz $<2^{18}$}& \multicolumn{2}{c|}{$2^{18}\leq$ nnz $<2^{20}$}& \multicolumn{2}{c|}{$2^{20}\leq$ nnz}&&\\
      &&&  Solved & Time &  Solved & Time &  Solved & Time &  Solved & Time \\
      \hline\hline
      \multirow{4}{*}{\rotatebox{90}{\bfseries OPF}}&\multirow{2}{*}{$10^{-4}$} & MadNLP (GPU) & \textbf{31} & 0.4166 & \textbf{24} & \textbf{2.6380} & \textbf{11} & \textbf{3.7040} & \textbf{66} & \textbf{1.6979}  \\
      && Ipopt (CPU)& \textbf{31} & 0.3970 & \textbf{24} & 5.0697 & 11 & 38.5053 & \textbf{66} & 5.3817  \\
      \cline{2-11}
      &\multirow{2}{*}{$10^{-8}$} & MadNLP (GPU) & 30 & 2.5037 & \textbf{24} & \textbf{4.6016} & 10 & \textbf{12.8040} & 64 & \textbf{4.6228}  \\
      && Ipopt (CPU) & \textbf{31} & 0.5100 & \textbf{24} & 5.4292 & 11 & 37.7818 & \textbf{66} & 5.5541  \\
      \hline
    \end{tabular}
  \end{center}
  \begin{itemize}
  \item \alert{Benchamrk set}: AC optimal power flow \citep{babaeinejadsarookolaeePowerGridLibrary2021}
  \item \alert{Hardware}: NVIDIA GV 100 GPU / Intel Xeon Gold 6130 CPU
  \item \alert{Time}: reported as SGM10$:= \prod_{i=1}^n (t_i + 10))^{1/n} - 10$, max wall time 900s 
  \end{itemize}
  \begin{block}{Observation}
    GPU solver is most effective for large-scale problems for moderate accuracy ($10^{-4}$)
  \end{block}
  \refbr{
    \fullcite{montoisonGPUImplementationSecondOrder2025}\\
    \fullcite{babaeinejadsarookolaeePowerGridLibrary2021}
  }
\end{frame}

\begin{frame}{Option 1: Lifted KKT---numerical results (COPS)}{\cite{montoisonGPUImplementationSecondOrder2025}}
  \begin{center}
    \scriptsize
    \begin{tabular}{|c|c|c|cc|cc|cc|cc|}
      \hline
      &\multirow{ 3}{*}{\bfseries Tol} & \multirow{ 3}{*}{\bfseries Solver} & \multicolumn{2}{c|}{\textbf{Small}}& \multicolumn{2}{c|}{\textbf{Medium}}& \multicolumn{2}{c|}{\textbf{Large}}& \multicolumn{2}{c|}{\multirow{2}{*}{\textbf{Total}}}\\
      &&& \multicolumn{2}{c|}{nnz $<2^{18}$}& \multicolumn{2}{c|}{$2^{18}\leq$ nnz $<2^{20}$}& \multicolumn{2}{c|}{$2^{20}\leq$ nnz}&&\\
      &&&  Solved & Time &  Solved & Time &  Solved & Time &  Solved & Time \\
      \hline\hline
      \multirow{4}{*}{\rotatebox{90}{\bfseries COPS}}&\multirow{2}{*}{$10^{-4}$} & MadNLP (GPU) & \textbf{13} & \textbf{0.8665} & \textbf{15} & \textbf{4.8665} & \textbf{16} & \textbf{3.8194} & \textbf{44} & \textbf{3.2314}  \\
      && Ipopt (CPU) & \textbf{13} & 5.2315 & \textbf{15} & 15.9701 & 15 & 45.8411 & 43 & 19.2243  \\
      \cline{2-11}
      &\multirow{2}{*}{$10^{-8}$} & MadNLP (GPU) & \textbf{13} & \textbf{0.8575} & \textbf{16} & \textbf{1.5572} & \textbf{16} & \textbf{8.3549} & \textbf{45} & \textbf{3.3797}  \\
      && Ipopt (CPU) & \textbf{13} & 5.9413 & \textbf{15} & 17.6758 & 15 & 40.8639 & 43 & 19.2999  \\
      \hline
    \end{tabular}
  \end{center}
  \begin{itemize}
    \item \alert{Benchamrk set}: COPS Benchmark \citep{dolanBenchmarkingOptimizationSoftware2001}
    \item \alert{Hardware}: NVIDIA GV 100 GPU / Intel Xeon Gold 6130 CPU
    \item \alert{Time}: reported as SGM10$:= \prod_{i=1}^n (t_i + 10))^{1/n} - 10$, max wall time 900s
  \end{itemize}
  \begin{block}{Observation}
    GPU solver is most effective for large-scale problems for moderate accuracy ($10^{-4}$)
  \end{block}
  \refbr{
    \fullcite{montoisonGPUImplementationSecondOrder2025}\\
    \fullcite{babaeinejadsarookolaeePowerGridLibrary2021}
  }
\end{frame}

% ---------------------------
\section{Option 2: Hybrid KKT}
% ---------------------------
\begin{frame}{Option 2: Hybrid KKT system}{ \cite{golubSolvingBlockStructuredIndefinite2003,regevHyKKTHybridDirectiterative2023,pacaudCondensedspaceMethodsNonlinear2024}}
  \begin{itemize}
  \item We keep the equality constraints $h(x)= 0$ and eliminate the inequalities (slack/dual):
    \begin{align*}
      &\begin{bmatrix}
        K_{\text{cond}} + \delta_p I & \nabla h(x)^\top
        \\ \nabla h(x) &  - \delta_d I
      \end{bmatrix}
        \begin{bmatrix}
          \phantom{-}d_x \\
          -d_{\lambda}
        \end{bmatrix}
        =      
        -\begin{bmatrix}
          r_x\\
          r_{\lambda}
        \end{bmatrix}\\
      &\xRightarrow[\text{\tiny (w/o changing solution)}]{\text{\tiny Regularization}}
        \begin{bmatrix}
          K_{\text{cond}} + \delta_p I + \rho  \nabla h(x)^\top \nabla h(x)& \nabla h(x)^\top
        \\ \nabla h(x) &  - \delta_d I
      \end{bmatrix}
        \begin{bmatrix}
          \phantom{-}d_x \\
          -d_{\lambda}
        \end{bmatrix}
        =      
        -\begin{bmatrix}
          r_x'\\
          r_{\lambda}
        \end{bmatrix}
    \end{align*}
    Then, the Schur complement can be solved with an iterative method (e.g., CG)
    \begin{align*}
      \Bigg(\underbrace{\nabla h(x)^\top \Big(\overbrace{K_{\text{cond}} + \delta_p I + \rho  \nabla h(x)^\top \nabla h(x)}^{\tikz[overlay]{\node {\scriptsize \alert{SPD for sufficiently large $\rho$ iff correct inertia}};}} \Big)^{-1} \nabla h(x)}_{\text{converges to } I \text{ as } \rho\rightarrow \infty}  + \delta_d I \Bigg) d_{\lambda} = r'_{\lambda} 
    \end{align*}
  \end{itemize}
  \refbr{
    \fullcite{golubSolvingBlockStructuredIndefinite2003}\\
    \fullcite{regevHyKKTHybridDirectiterative2023}\\
    \fullcite{pacaudCondensedspaceMethodsNonlinear2024}
  }
\end{frame}

% ---------------------------
\section{Beyond IPM KKT}
% ---------------------------
\begin{frame}{Options 3, 4, 5, ...}
  \begin{itemize}
  \item There can be lots of other ways to implement pivoting-free solvers
  \item \alert{MadIPM}: Solver for convex quadratic programs; uses regularization to avoid pivoting \citep{montoisonGPUImplementationSecondOrder2025}
  \item \alert{MadNCL}: ALM-based algorithm---ALM is more \alert{GPU-friendly} due to the quadratic penalty term. Uses nonlinearly-constrained Lagrangian (NCL) formulation and applies condensation techniques \citep{montoisonMadNCLGPUImplementation2025}
  \item Directly solving augmented systems without pivoting? ---currently under investigation
  \end{itemize}
\end{frame}

% ---------------------------
\section{Conclusion}
% ---------------------------
\begin{frame}{Concluding remarks}
  \begin{itemize}
  \item It is an exciting time to develop optimization solvers!
  \item Existing GPU solvers have focused on \alert{factorization-free} (e.g. first-order) methods, but
    \begin{center}
      \text{GPU optimization solver} $\supsetneq$ \text{Factorization-free solver}.
    \end{center}
  \item With \alert{GPU direct solvers}, \alert{second-order methods} on GPUs has now become possible
  \item To harness these GPU direct solvers, we need \alert{pivoting-free algorithms}
  \item We presented \alert{Lifted KKT} and \alert{Hybrid KKT}, but there can be many others
  \end{itemize}
  \begin{center}
    Check out our project page!\\
    \url{https://madsuite.org/}
  \end{center}
\end{frame}

\AtNextBibliography{\tiny}
\setbeamertemplate{bibliography item}{}
\begin{frame}{References}
  \tikz[text width=1.1\textwidth,xscale=.9,transform shape]{
    \node at (current page.center) {\printbibliography[heading=none]};
  }
\end{frame}

\end{document}

%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: t
%%% End:


